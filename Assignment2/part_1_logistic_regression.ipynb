{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fsF8yRafNKjw"
   },
   "source": [
    "This notebook trains a binary classifier on a dataset which contains movie reviews which are labelled as containing either *positive* or *negative* sentiment towards the movie. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzUZxeMbRPoM"
   },
   "source": [
    "First we will install *sklearn* which we will be using to do the machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UV8dcUsoOA_l",
    "outputId": "d3c21180-7dba-4f8e-c332-ce3d2cc52246"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ekmP1Ry1R00y"
   },
   "source": [
    "Next we will install the dataset. We will use the IMDB sentiment analysis dataset available from the [huggingface datasets library](https://huggingface.co/datasets/imdb) and described in [Maas et al. 2011](https://aclanthology.org/P11-1015.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yd0bLG6nOE4D",
    "outputId": "97b334c0-50df-4786-9bca-8634d43bc903"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2h6B6dXHSP6X"
   },
   "source": [
    "Now let's load the IMDB training set. We will print out the last instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "referenced_widgets": [
      "368e31f92e0d4d1c87ee49914f1ffc6c",
      "63e5c1aa5ae149ddb658f8dfe71239f4",
      "8f47145a1d2c42bb96b2197cce11156c",
      "9cd069a843c446d6bc9bc289d3aa0b74",
      "1fdeebdafba14d0c9ab234835739da3f",
      "cc89fd8c3e9546c48f5c53c5880deb19",
      "d1a6da014a0e4c7f8361e1beb0b17788",
      "d73e89c174b64492b4bf6e241948803f",
      "ab8e3e09052140cda8630e66b1085253",
      "08743a7e09354493be8c6bb1ca047e70",
      "fb1c08cb7c2d49debc140370ee19e7b5"
     ]
    },
    "id": "XOO5rQFHUg8D",
    "outputId": "4e8df3b5-2f0c-4c40-9296-3c0336f94a14"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0074f63fea3f42bda56d1b697b9cb813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.31k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4b03b19046b489c9be00a400d48ab38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/2.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55b9bc05bed6474bb8793e077177bed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/7.59k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset imdb/plain_text to C:/Users/adamt/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f6f7523c00436594a6599e968787bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/84.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset imdb downloaded and prepared to C:/Users/adamt/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e1b7fa8b9e446e58ce1e2d215e3970f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "imdb_dataset = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "enwDYpN7Hwgw"
   },
   "source": [
    "Let's convert the training data into the format expected by scikit-learn - a list of input vectors (documents) and a list of associated output labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H8xfDeEMWq1o",
    "outputId": "4db18b9b-6691-49c1-8798-896307abc7b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The story centers around Barry McKenzie who must go to England if he wishes to claim his inheritance. Being about the grossest Aussie shearer ever to set foot outside this great Nation of ours there is something of a culture clash and much fun and games ensue. The songs of Barry McKenzie(Barry Crocker) are highlights.\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "train_dataset = imdb_dataset['train']\n",
    "train_data = []\n",
    "train_data_labels = []\n",
    "for item in train_dataset:\n",
    "  train_data.append(item['text'])\n",
    "  train_data_labels.append(item['label'])\n",
    "print(train_data[-1])\n",
    "print(train_data_labels[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wI6ab7wOIOu2"
   },
   "source": [
    "We'll use the CountVectorizer class to extract the words in each review as the features the algorithm will learn from. Each document is represented as a 200 dimension vector of word counts. Only the 200 most frequent words are used in this version. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vDYo_rZkXZUZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(analyzer='word',max_features=200,lowercase=True)\n",
    "features = vectorizer.fit_transform(train_data).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7l9Xg1TTfkV"
   },
   "source": [
    "As a sanity check, let's check we have a 2-d array where each row is one of the 25,000 instances and each column is one of 200 words. Print out the words that will be used for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2oW0zYH0TdPm",
    "outputId": "c72860b4-64b9-4841-f2a3-985f286e0bf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 200)\n",
      "['10' 'about' 'acting' 'action' 'actors' 'actually' 'after' 'again' 'all'\n",
      " 'also' 'an' 'and' 'another' 'any' 'are' 'around' 'as' 'at' 'back' 'bad'\n",
      " 'be' 'because' 'been' 'before' 'being' 'best' 'better' 'between' 'big'\n",
      " 'both' 'br' 'but' 'by' 'can' 'cast' 'character' 'characters' 'could'\n",
      " 'did' 'didn' 'director' 'do' 'does' 'doesn' 'don' 'down' 'end' 'enough'\n",
      " 'even' 'ever' 'every' 'fact' 'few' 'film' 'films' 'find' 'first' 'for'\n",
      " 'from' 'funny' 'get' 'give' 'go' 'going' 'good' 'got' 'great' 'had' 'has'\n",
      " 'have' 'he' 'her' 'here' 'him' 'his' 'horror' 'how' 'however' 'if' 'in'\n",
      " 'into' 'is' 'it' 'its' 'just' 'know' 'life' 'like' 'little' 'long' 'look'\n",
      " 'lot' 'love' 'made' 'make' 'makes' 'man' 'many' 'may' 'me' 'more' 'most'\n",
      " 'movie' 'movies' 'much' 'my' 'never' 'new' 'no' 'not' 'nothing' 'now'\n",
      " 'of' 'off' 'old' 'on' 'one' 'only' 'or' 'original' 'other' 'out' 'over'\n",
      " 'own' 'part' 'people' 'plot' 'pretty' 'quite' 're' 'real' 'really'\n",
      " 'right' 'same' 'say' 'scene' 'scenes' 'see' 'seems' 'seen' 'series' 'she'\n",
      " 'should' 'show' 'so' 'some' 'something' 'still' 'story' 'such' 'take'\n",
      " 'than' 'that' 'the' 'their' 'them' 'then' 'there' 'these' 'they' 'thing'\n",
      " 'things' 'think' 'this' 'those' 'though' 'thought' 'through' 'time' 'to'\n",
      " 'too' 'two' 'up' 'us' 've' 'very' 'want' 'was' 'watch' 'watching' 'way'\n",
      " 'we' 'well' 'were' 'what' 'when' 'where' 'which' 'while' 'who' 'why'\n",
      " 'will' 'with' 'work' 'world' 'would' 'years' 'you' 'young' 'your']\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)\n",
    "print(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O_vqmxuNJKXs"
   },
   "source": [
    "Split the data into a training and validation (dev) set. We'll use the validation set to test our model. We'll use 75% of the data for training and 25% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "IgFqymeXcGzG"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(features,train_data_labels,train_size=0.75,random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yz4X0a8sVEva"
   },
   "source": [
    "We will use Logistic Regression to do the classification. Create the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Yn-H8cvpZMr9"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VHVdauzFJSWY"
   },
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "TFPY4JrcZkFZ"
   },
   "outputs": [],
   "source": [
    "model = model.fit(X=X_train,y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQTvGAtwJWn3"
   },
   "source": [
    "Test the model on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "xS22mi3sgr40"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HESEphJ1VvjQ"
   },
   "source": [
    "Now let's calculate the accuracy of the model's predictions on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ak_-Ah-Ig1bz",
    "outputId": "8e63b2f3-d4be-48df-a02d-0a27bedcd9fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76368\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_val,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DnuD9h7FMtMV"
   },
   "source": [
    "Now let's prepare some test data. Use the same 1000 as in the BERT notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z97vW6N2M4wq",
    "outputId": "9eea7217-f369-4dc3-80e7-7aa0cce7d7ff"
   },
   "outputs": [],
   "source": [
    "test_dataset = imdb_dataset['test'].shuffle(seed=42).select(range(1000))\n",
    "test_data = []\n",
    "test_data_labels = []\n",
    "for item in test_dataset:\n",
    "  test_data.append(item['text'])\n",
    "  test_data_labels.append(item['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7icRGUmYNHeJ"
   },
   "source": [
    "Apply the model to the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "KToFQzcoNJhL"
   },
   "outputs": [],
   "source": [
    "test_pred=model.predict(vectorizer.transform(test_data).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rOpL2RG9NRuu",
    "outputId": "dcb791fe-bf87-4b41-a34f-c8512d25e13d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.74\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_pred,test_data_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2yl2AgiPJK5"
   },
   "source": [
    "## Possible improvements\n",
    "\n",
    "In this section, we will consider the changes that can be made to the features and model that will improve the performance.\n",
    "\n",
    "### Stop word removal\n",
    "\n",
    "Stop words are words that are typically not of importance, so they can be removed from the corpus. This is task dependent as some tasks make use of stop words such as predicting the next word in a sequence.\n",
    "\n",
    "For our usecase, sentiment analysis, stop words such as the, at and on are not of importance for determining the sentiment of a review. There are lists of stop words available through sklearn and nltk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "P6HHIuCalPva"
   },
   "outputs": [],
   "source": [
    "# Import nltk and the stop words list.\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oj_4Krw1laxi",
    "outputId": "684049f8-7892-49f2-9dc5-8fa1efd7a838"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\adamt\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
      "179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "# Download the stop words list and print the list and the length.\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "print(stop_words)\n",
    "print(len(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GK0AcEWffuUk",
    "outputId": "e1eb3e84-ab2e-4191-8d95-29c7489493bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'across', 'without', 'onto', 'this', 'due', 'your', 'beyond', 'thru', 'system', 'latterly', 'see', 'otherwise', 'were', 'find', 'eleven', 'what', 'hereafter', 'thus', 'many', 'however', 'more', 're', 'neither', 'someone', 'these', 'to', 'its', 'never', 'himself', 'co', 'even', 'five', 'alone', 'he', 'will', 'couldnt', 'off', 'for', 'not', 'until', 'nor', 'therein', 'get', 'whereby', 'hers', 'yours', 'show', 'very', 'often', 'cannot', 'also', 'while', 'fifty', 'sincere', 'next', 'can', 'been', 'inc', 'became', 'seeming', 'than', 'behind', 'anywhere', 'how', 'whether', 'with', 'am', 'thereby', 'ever', 'some', 'again', 'because', 'why', 'towards', 'ie', 'have', 'six', 'throughout', 'anyway', 'two', 'should', 'else', 'those', 'whereas', 'mill', 'whose', 'against', 'has', 'another', 'either', 'within', 'via', 'anyhow', 'top', 'nowhere', 'during', 'whoever', 'whence', 'thereafter', 'un', 'only', 'anyone', 'namely', 'cry', 'which', 'becomes', 'upon', 'bottom', 'them', 'at', 'cant', 'yet', 'bill', 'side', 'empty', 'around', 'on', 'amongst', 'myself', 'herein', 'hence', 'our', 'call', 'ltd', 'was', 'thick', 'wherever', 'who', 'thin', 'others', 'keep', 'here', 'already', 'an', 'enough', 'part', 'full', 'being', 'so', 'above', 'describe', 'somewhere', 'thence', 'mostly', 'once', 'amoungst', 'per', 'among', 'between', 'themselves', 'then', 'every', 'about', 'through', 'amount', 'yourself', 'hereupon', 'are', 'their', 'as', 'out', 'con', 'it', 'everywhere', 'yourselves', 'over', 'along', 'therefore', 'detail', 'her', 'or', 'up', 'whereupon', 'whereafter', 'may', 'where', 'several', 'always', 'something', 'found', 'interest', 'had', 'nevertheless', 'etc', 'and', 'below', 'into', 'moreover', 'ourselves', 'one', 'twelve', 'least', 'might', 'must', 'well', 'other', 'would', 'meanwhile', 'whatever', 'nothing', 'almost', 'give', 'together', 'my', 'wherein', 'nine', 'still', 'much', 'after', 'me', 'whither', 'forty', 'please', 'him', 'if', 'whom', 'indeed', 'seem', 'by', 'both', 'ours', 'is', 'sometimes', 'when', 'done', 'anything', 'rather', 'become', 'becoming', 'go', 'there', 'afterwards', 'any', 'down', 'no', 'somehow', 'four', 'less', 'although', 'you', 'his', 'that', 'toward', 'now', 'seems', 'herself', 'of', 'move', 'beforehand', 'further', 'but', 'in', 'eight', 'besides', 'each', 'serious', 'all', 'latter', 'thereupon', 'twenty', 'ten', 'first', 'noone', 'made', 'formerly', 'hereby', 'too', 'own', 'perhaps', 'except', 'whole', 'fire', 'itself', 'beside', 'such', 'third', 'under', 'since', 'eg', 'could', 'everyone', 'the', 'us', 'elsewhere', 'hasnt', 'sixty', 'back', 'from', 'a', 'few', 'nobody', 'seemed', 'de', 'most', 'they', 'be', 'put', 'hundred', 'none', 'former', 'take', 'before', 'she', 'fill', 'front', 'we', 'i', 'fifteen', 'last', 'mine', 'whenever', 'three', 'do', 'though', 'everything', 'sometime', 'name', 'same'})\n",
      "318\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import _stop_words\n",
    " \n",
    "# Assign the sklearn stopword list to a variable and print the list and the length.\n",
    "sklearn_stop_words = _stop_words.ENGLISH_STOP_WORDS\n",
    "print(sklearn_stop_words)\n",
    "print(len(sklearn_stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k3H7kSVrR7Z0"
   },
   "source": [
    "Looking at the two lists we can see that the sklearn list is longer with 318 words while the nltk list has 179. Some of the words in the sklearn list seem like they may be of importance for determining the sentiment, such as nothing, fire, sincere and cry.\n",
    "\n",
    "We can test both stop word lists, but I believe that the nltk stop word list may be the better suited for our task.\n",
    "\n",
    "To implement the removal of stop words we can pass this list to the CountVectorizer to remove these words from the corpus.\n",
    "\n",
    "### Word document frequency\n",
    "\n",
    "Typically, words that appear in many examples of both positive and negative reviews are not very useful for discerning the two. In a similar way, words that occur only in a single document and are unique will not be very useful in classifying a document.\n",
    "\n",
    "These can both be implemented through parameters in the CountVectorizer. So we will only consider words that appear a reasonable number of times and will likely be useful for discerning the class.\n",
    "\n",
    "### N-gram count\n",
    "\n",
    "The CountVectorizer offers the option of creating bigrams and including these in the training corpus. This involves taking every pair of words that appear in the corpus and treating them like a new word. This can be very usefil for terms such as 'special effects', which may be a word for discerning the class.\n",
    "\n",
    "### TF-IDF features\n",
    "\n",
    "Sklearn offers a text feature extractor that generates tf-idf scores for words in a corpus. We can pass our results from the CountVectorizer to get these scores. The only aspect that this can make an improvement on is the term frequencies having less impact on the prediction, which would mean a more diverse occurence of positive words would be more meaningful than lots of occurrences of the same word.\n",
    "\n",
    "### Max features\n",
    "\n",
    "This is the most obvious change that can be made to improve the models accuracy. Increasing the number of features gives the model more data to work with, but some of this may not be useful. Including all of the data is not wise as there is a diminishing return on adding more features. We trade added complexity for a marginal improvement in accuracy when we reach a certain point. For this reason, I will be focusing more on limiting the number of features to those that are important or useful \n",
    "\n",
    "To test all of these I will make use of GridSearchCV to test combinations for all of these parameters. The only segment I cannot introduce here is the tf-idf feature extractor as it would need to be part of the pipeline. I will evaluate this after I have found the best parameters for the rest of the parameters I would like to use.\n",
    "\n",
    "My prediction for a good set of parameters will be an increased number of features, the removal of words that occur too frequently or infrequently. Stop word removal may be of use, but if we remove common words these will likely be removed. N-gram length may be useful for finding terms consisting of either one or two words. Lastly, tf-idf may be useful to get a balance between just taking whether a word occurs in a text and having the counts. This means that an increased count does have a bigger impact, but not as much as if we took the raw counts themselves. This will likely lead to better understanding of how these words and their occurrences impact the classification of a document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U6TZB44ldyUd",
    "outputId": "06a598b5-8e46-49e3-900e-f874ea18acb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 288 candidates, totalling 1152 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adamt\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "216 fits failed out of a total of 1152.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "216 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\adamt\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\adamt\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\pipeline.py\", line 378, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\adamt\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\pipeline.py\", line 336, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\ProgramData\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\adamt\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\pipeline.py\", line 870, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\adamt\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1352, in fit_transform\n",
      "    raise ValueError(\"max_df corresponds to < documents than min_df\")\n",
      "ValueError: max_df corresponds to < documents than min_df\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\adamt\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.7642  0.77068 0.78416 0.75996 0.77072 0.7828  0.7642  0.77068 0.78504\n",
      " 0.75996 0.77072 0.78416 0.7642  0.77068 0.78416 0.75996 0.77072 0.7816\n",
      " 0.7642  0.77068 0.78416 0.75996 0.77072 0.7828  0.8306  0.82948 0.82476\n",
      " 0.81904 0.82944 0.8248  0.82352 0.81424 0.80656 0.81888 0.8144  0.8066\n",
      " 0.8306  0.82952 0.82536 0.81904 0.82904 0.825   0.83068 0.82948 0.82476\n",
      " 0.819   0.8292  0.82512 0.8484  0.84112 0.83948 0.8368  0.8412  0.83856\n",
      " 0.82352 0.81424 0.80656 0.82876 0.8144  0.8066  0.84808 0.84164 0.83984\n",
      " 0.83684 0.84164 0.83912 0.8496  0.8424  0.83976 0.83684 0.84276 0.839\n",
      " 0.76516 0.77068 0.78416 0.75908 0.77072 0.7828  0.76516 0.77068 0.78504\n",
      " 0.75908 0.77072 0.78416 0.76516 0.77068 0.78416 0.75908 0.77072 0.7816\n",
      " 0.76516 0.77068 0.78416 0.75908 0.77072 0.7828  0.83072 0.82948 0.82476\n",
      " 0.8176  0.82944 0.8248  0.82272 0.81424 0.80656 0.81884 0.8144  0.8066\n",
      " 0.83072 0.82952 0.82536 0.8176  0.82904 0.825   0.83072 0.82948 0.82476\n",
      " 0.8176  0.8292  0.82512 0.84848 0.84112 0.83948 0.83684 0.8412  0.83856\n",
      " 0.82272 0.81424 0.80656 0.8292  0.8144  0.8066  0.84852 0.84164 0.83984\n",
      " 0.83688 0.84164 0.83912 0.84896 0.8424  0.83976 0.83724 0.84276 0.839\n",
      " 0.76596 0.77068 0.78416 0.76144 0.77072 0.7828  0.76596 0.77068 0.78504\n",
      " 0.76144 0.77072 0.78416 0.76596 0.77068 0.78416 0.76144 0.77072 0.7816\n",
      " 0.76596 0.77068 0.78416 0.76144 0.77072 0.7828  0.83232 0.82948 0.82476\n",
      " 0.81868 0.82944 0.8248  0.82616 0.81424 0.80656 0.81984 0.8144  0.8066\n",
      " 0.83224 0.82952 0.82536 0.81864 0.82904 0.825   0.83232 0.82948 0.82476\n",
      " 0.81876 0.8292  0.82512 0.84912 0.84112 0.83948 0.83776 0.8412  0.83856\n",
      " 0.82616 0.81424 0.80656 0.83004 0.8144  0.8066  0.84912 0.84164 0.83984\n",
      " 0.838   0.84164 0.83912 0.85032 0.8424  0.83976 0.83772 0.84276 0.839\n",
      " 0.49496 0.49508 0.4962  0.49804 0.49824 0.49852     nan     nan     nan\n",
      "     nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "     nan     nan     nan     nan     nan     nan 0.4932  0.49312 0.4926\n",
      " 0.49332 0.4934  0.49404     nan     nan     nan     nan     nan     nan\n",
      "     nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "     nan     nan     nan 0.48924 0.48816 0.4884  0.49104 0.49128 0.49264\n",
      "     nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "     nan     nan     nan     nan     nan     nan     nan     nan     nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.850):\n",
      "{'vectorizer__max_df': 0.9, 'vectorizer__max_features': 1000, 'vectorizer__min_df': 0.02, 'vectorizer__ngram_range': (1, 1), 'vectorizer__stop_words': None}\n"
     ]
    }
   ],
   "source": [
    "# import GridSearchCV and Pipeline.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define a CountVectorizer to use\n",
    "vectorizer = CountVectorizer(lowercase=True)\n",
    "\n",
    "# Create a LogisticRegression model and set the max iterations to be higher as\n",
    "# there were times while testing that the model did not converge in 100 iterations.\n",
    "logistic = LogisticRegression(max_iter=400)\n",
    "\n",
    "# Create the pipeline.\n",
    "pipe = Pipeline(steps=[(\"vectorizer\", vectorizer), (\"logistic\", logistic)])\n",
    "\n",
    "# Define the parameters to test.\n",
    "param_grid = {\n",
    "    \"vectorizer__stop_words\": [None, stop_words, sklearn_stop_words],\n",
    "    \"vectorizer__max_df\": [0.7, 0.8, 0.9, 1.0],\n",
    "    \"vectorizer__min_df\": [0, 0.05, 0.01, 0.02],\n",
    "    \"vectorizer__ngram_range\": [(1,1), (1,2)],\n",
    "    \"vectorizer__max_features\": [200, 500, 1000],\n",
    "}\n",
    "\n",
    "# Initialize the GridSearchCV object.\n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=8, verbose=3, cv=4)\n",
    "\n",
    "# Run the GridSearchCV with all of the data, we will test it on the same sub\n",
    "# sample as before when we find the best parameters.\n",
    "search.fit(train_data, train_data_labels)\n",
    "\n",
    "# Print the best parameters.\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqfnbKfy6qnm"
   },
   "source": [
    "Results here\n",
    "\n",
    "Now we try these parameters with the original train and test split and also the separate test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the CountVectorizer with the parameters\n",
    "vectorizer = CountVectorizer(lowercase=True, max_df=1.0, max_features=1000, min_df=0.02, ngram_range=(1,1)) #lowercase=True\n",
    "\n",
    "# Generate the features.\n",
    "features = vectorizer.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2xQ6FCMgmIeN",
    "outputId": "6b1b8bdd-4b90-4aae-90f8-d4c3fd90fbfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 1000)\n",
      "['10' '20' '30' '80' 'able' 'about' 'above' 'absolutely' 'across' 'act'\n",
      " 'acted' 'acting' 'action' 'actor' 'actors' 'actress' 'actual' 'actually'\n",
      " 'add' 'admit' 'after' 'again' 'against' 'age' 'ago' 'agree' 'air' 'all'\n",
      " 'almost' 'alone' 'along' 'already' 'also' 'although' 'always' 'am'\n",
      " 'amazing' 'america' 'american' 'among' 'an' 'animation' 'annoying'\n",
      " 'another' 'any' 'anyone' 'anything' 'anyway' 'apart' 'apparently'\n",
      " 'appear' 'appears' 'are' 'aren' 'around' 'art' 'as' 'ask' 'at'\n",
      " 'atmosphere' 'attempt' 'attempts' 'attention' 'audience' 'average'\n",
      " 'avoid' 'away' 'awful' 'baby' 'back' 'background' 'bad' 'badly' 'based'\n",
      " 'basically' 'be' 'beautiful' 'beauty' 'became' 'because' 'become'\n",
      " 'becomes' 'been' 'before' 'begin' 'beginning' 'begins' 'behind' 'being'\n",
      " 'believable' 'believe' 'best' 'better' 'between' 'beyond' 'big' 'bit'\n",
      " 'black' 'blood' 'body' 'book' 'boring' 'both' 'box' 'boy' 'br' 'break'\n",
      " 'brilliant' 'bring' 'brings' 'british' 'brother' 'brought' 'budget'\n",
      " 'bunch' 'business' 'but' 'buy' 'by' 'call' 'called' 'came' 'camera' 'can'\n",
      " 'cannot' 'car' 'care' 'career' 'case' 'cast' 'casting' 'caught' 'certain'\n",
      " 'certainly' 'chance' 'change' 'character' 'characters' 'cheap' 'check'\n",
      " 'cheesy' 'child' 'children' 'cinema' 'cinematography' 'city' 'class'\n",
      " 'classic' 'clear' 'clearly' 'close' 'co' 'come' 'comedy' 'comes' 'comic'\n",
      " 'coming' 'comment' 'comments' 'compared' 'complete' 'completely'\n",
      " 'considering' 'convincing' 'cool' 'copy' 'could' 'couldn' 'country'\n",
      " 'couple' 'course' 'crap' 'crazy' 'create' 'credits' 'creepy' 'crime'\n",
      " 'cut' 'cute' 'dance' 'dark' 'daughter' 'david' 'day' 'days' 'dead' 'deal'\n",
      " 'death' 'decent' 'decided' 'decides' 'deep' 'definitely' 'deserves'\n",
      " 'despite' 'development' 'dialog' 'dialogue' 'did' 'didn' 'die'\n",
      " 'different' 'difficult' 'directed' 'directing' 'direction' 'director'\n",
      " 'directors' 'disappointed' 'do' 'documentary' 'does' 'doesn' 'doing'\n",
      " 'don' 'done' 'doubt' 'down' 'drama' 'dramatic' 'dream' 'due' 'dull'\n",
      " 'dumb' 'during' 'dvd' 'each' 'earlier' 'early' 'earth' 'easily' 'easy'\n",
      " 'editing' 'effect' 'effects' 'effort' 'either' 'elements' 'else'\n",
      " 'emotional' 'end' 'ended' 'ending' 'ends' 'english' 'enjoy' 'enjoyable'\n",
      " 'enjoyed' 'enough' 'entertaining' 'entertainment' 'entire' 'episode'\n",
      " 'episodes' 'era' 'especially' 'etc' 'even' 'events' 'eventually' 'ever'\n",
      " 'every' 'everyone' 'everything' 'evil' 'exactly' 'example' 'excellent'\n",
      " 'except' 'expect' 'expected' 'expecting' 'experience' 'extremely' 'eye'\n",
      " 'eyes' 'face' 'fact' 'fails' 'fairly' 'fall' 'falls' 'familiar' 'family'\n",
      " 'famous' 'fan' 'fans' 'fantastic' 'far' 'fast' 'father' 'favorite'\n",
      " 'feature' 'features' 'feel' 'feeling' 'feels' 'felt' 'female' 'few'\n",
      " 'fight' 'fighting' 'figure' 'filled' 'film' 'filmed' 'films' 'final'\n",
      " 'finally' 'find' 'finds' 'fine' 'fire' 'first' 'five' 'flat' 'flick'\n",
      " 'follow' 'following' 'for' 'forced' 'forget' 'form' 'forward' 'found'\n",
      " 'four' 'free' 'french' 'friend' 'friends' 'from' 'front' 'full' 'fun'\n",
      " 'funny' 'further' 'future' 'game' 'gave' 'general' 'genre' 'george' 'get'\n",
      " 'gets' 'getting' 'girl' 'girlfriend' 'girls' 'give' 'given' 'gives'\n",
      " 'giving' 'go' 'god' 'goes' 'going' 'gone' 'good' 'gore' 'got' 'great'\n",
      " 'greatest' 'group' 'guess' 'guy' 'guys' 'had' 'half' 'hand' 'hands'\n",
      " 'happen' 'happened' 'happens' 'happy' 'hard' 'hardly' 'has' 'hate' 'have'\n",
      " 'haven' 'having' 'he' 'head' 'hear' 'heard' 'heart' 'hell' 'help' 'her'\n",
      " 'here' 'hero' 'herself' 'high' 'highly' 'hilarious' 'him' 'himself' 'his'\n",
      " 'history' 'hit' 'hold' 'hollywood' 'home' 'hope' 'horrible' 'horror'\n",
      " 'hot' 'hour' 'hours' 'house' 'how' 'however' 'huge' 'human' 'humor'\n",
      " 'husband' 'idea' 'ideas' 'if' 'imagine' 'imdb' 'important' 'in'\n",
      " 'including' 'incredibly' 'indeed' 'inside' 'instead' 'interest'\n",
      " 'interested' 'interesting' 'into' 'involved' 'is' 'isn' 'it' 'its'\n",
      " 'itself' 'jack' 'james' 'job' 'john' 'joke' 'jokes' 'just' 'keep' 'keeps'\n",
      " 'kept' 'kid' 'kids' 'kill' 'killed' 'killer' 'killing' 'kind' 'king'\n",
      " 'knew' 'know' 'known' 'knows' 'lack' 'lady' 'lame' 'large' 'last' 'late'\n",
      " 'later' 'laugh' 'laughs' 'lead' 'leading' 'leads' 'learn' 'least' 'leave'\n",
      " 'leaves' 'left' 'less' 'let' 'level' 'life' 'light' 'like' 'liked' 'line'\n",
      " 'lines' 'list' 'little' 'live' 'lives' 'living' 'll' 'local' 'long'\n",
      " 'look' 'looked' 'looking' 'looks' 'lost' 'lot' 'lots' 'love' 'loved'\n",
      " 'low' 'made' 'main' 'major' 'make' 'makes' 'making' 'male' 'man'\n",
      " 'manages' 'many' 'mark' 'married' 'masterpiece' 'material' 'matter' 'may'\n",
      " 'maybe' 'me' 'mean' 'means' 'meant' 'meet' 'meets' 'memorable' 'men'\n",
      " 'mention' 'mentioned' 'mess' 'message' 'michael' 'middle' 'might' 'mind'\n",
      " 'minute' 'minutes' 'miss' 'missed' 'missing' 'modern' 'moment' 'moments'\n",
      " 'money' 'more' 'most' 'mostly' 'mother' 'move' 'movie' 'movies' 'moving'\n",
      " 'mr' 'much' 'murder' 'music' 'musical' 'must' 'my' 'myself' 'mystery'\n",
      " 'name' 'named' 'nature' 'near' 'nearly' 'need' 'needed' 'needs' 'neither'\n",
      " 'never' 'new' 'next' 'nice' 'night' 'no' 'non' 'none' 'nor' 'not' 'note'\n",
      " 'nothing' 'novel' 'now' 'nudity' 'number' 'obvious' 'obviously' 'odd'\n",
      " 'off' 'often' 'oh' 'ok' 'okay' 'old' 'older' 'on' 'once' 'one' 'ones'\n",
      " 'only' 'open' 'opening' 'opinion' 'or' 'order' 'original' 'oscar' 'other'\n",
      " 'others' 'otherwise' 'our' 'out' 'outside' 'over' 'overall' 'own' 'pace'\n",
      " 'parents' 'part' 'particular' 'particularly' 'parts' 'past' 'paul' 'pay'\n",
      " 'people' 'perfect' 'perfectly' 'performance' 'performances' 'perhaps'\n",
      " 'period' 'person' 'personal' 'peter' 'picture' 'piece' 'place' 'plain'\n",
      " 'play' 'played' 'playing' 'plays' 'please' 'plenty' 'plot' 'plus' 'point'\n",
      " 'points' 'police' 'poor' 'poorly' 'popular' 'portrayed' 'possible'\n",
      " 'possibly' 'potential' 'power' 'powerful' 'predictable' 'premise'\n",
      " 'present' 'pretty' 'previous' 'probably' 'problem' 'problems' 'produced'\n",
      " 'production' 'public' 'pure' 'put' 'quality' 'question' 'quickly' 'quite'\n",
      " 'rate' 'rather' 'rating' 're' 'read' 'reading' 'real' 'realistic'\n",
      " 'reality' 'realize' 'really' 'reason' 'reasons' 'recently' 'recommend'\n",
      " 'red' 'relationship' 'release' 'released' 'remember' 'rent' 'rest'\n",
      " 'result' 'return' 'review' 'reviews' 'rich' 'richard' 'ridiculous'\n",
      " 'right' 'robert' 'rock' 'role' 'roles' 'romance' 'romantic' 'room' 'run'\n",
      " 'running' 'sad' 'sadly' 'said' 'same' 'save' 'saw' 'say' 'saying' 'says'\n",
      " 'scary' 'scene' 'scenes' 'school' 'score' 'screen' 'screenplay' 'script'\n",
      " 'second' 'see' 'seeing' 'seem' 'seemed' 'seems' 'seen' 'self' 'sense'\n",
      " 'sequel' 'sequence' 'sequences' 'series' 'serious' 'seriously' 'set'\n",
      " 'sets' 'setting' 'several' 'sex' 'sexual' 'shame' 'she' 'short' 'shot'\n",
      " 'shots' 'should' 'show' 'showing' 'shown' 'shows' 'side' 'silly'\n",
      " 'similar' 'simple' 'simply' 'since' 'single' 'sister' 'sit' 'situation'\n",
      " 'slightly' 'slow' 'small' 'so' 'society' 'some' 'somehow' 'someone'\n",
      " 'something' 'sometimes' 'somewhat' 'son' 'song' 'songs' 'soon' 'sorry'\n",
      " 'sort' 'sound' 'sounds' 'soundtrack' 'space' 'special' 'spent' 'spoilers'\n",
      " 'stage' 'stand' 'star' 'stars' 'start' 'started' 'starts' 'stay' 'still'\n",
      " 'stop' 'stories' 'story' 'storyline' 'straight' 'strange' 'street'\n",
      " 'strong' 'stuff' 'stupid' 'style' 'subject' 'success' 'such' 'superb'\n",
      " 'supporting' 'supposed' 'sure' 'surprise' 'surprised' 'suspense' 'sweet'\n",
      " 'take' 'taken' 'takes' 'taking' 'tale' 'talent' 'talented' 'talk'\n",
      " 'talking' 'team' 'television' 'tell' 'telling' 'tells' 'ten' 'terrible'\n",
      " 'than' 'that' 'theater' 'their' 'them' 'theme' 'themselves' 'then'\n",
      " 'there' 'these' 'they' 'thing' 'things' 'think' 'thinking' 'third'\n",
      " 'those' 'though' 'thought' 'three' 'thriller' 'through' 'throughout'\n",
      " 'time' 'times' 'title' 'today' 'together' 'told' 'tom' 'too' 'took' 'top'\n",
      " 'total' 'totally' 'towards' 'town' 'tried' 'tries' 'true' 'truly' 'truth'\n",
      " 'try' 'trying' 'turn' 'turned' 'turns' 'tv' 'twist' 'two' 'type'\n",
      " 'typical' 'under' 'understand' 'unfortunately' 'unique' 'unless' 'unlike'\n",
      " 'until' 'up' 'upon' 'us' 'use' 'used' 'uses' 'using' 'usual' 'usually'\n",
      " 'various' 've' 'version' 'very' 'video' 'view' 'viewer' 'viewers'\n",
      " 'viewing' 'violence' 'voice' 'wait' 'waiting' 'want' 'wanted' 'wants'\n",
      " 'war' 'was' 'wasn' 'waste' 'wasted' 'watch' 'watched' 'watching' 'way'\n",
      " 'ways' 'we' 'weak' 'weird' 'well' 'went' 'were' 'what' 'whatever' 'when'\n",
      " 'where' 'whether' 'which' 'while' 'white' 'who' 'whole' 'whom' 'whose'\n",
      " 'why' 'wife' 'will' 'william' 'wish' 'with' 'within' 'without' 'woman'\n",
      " 'women' 'won' 'wonder' 'wonderful' 'word' 'words' 'work' 'worked'\n",
      " 'working' 'works' 'world' 'worse' 'worst' 'worth' 'would' 'wouldn'\n",
      " 'write' 'writer' 'writers' 'writing' 'written' 'wrong' 'wrote' 'year'\n",
      " 'years' 'yes' 'yet' 'york' 'you' 'young' 'your' 'yourself']\n"
     ]
    }
   ],
   "source": [
    "# Print out the shape of features and the feature names.\n",
    "print(features.shape)\n",
    "print(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "G7jMGbLZmusM"
   },
   "outputs": [],
   "source": [
    "# Split the data into train and test the same as the demonstration.\n",
    "X_train, X_val, y_train, y_val = train_test_split(features,train_data_labels,train_size=0.75,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "eKiOBceLmW3s"
   },
   "outputs": [],
   "source": [
    "# Create a new LogisticRegression model.\n",
    "model = LogisticRegression(max_iter=400)\n",
    "\n",
    "# Train the model on the training data.\n",
    "model = model.fit(X=X_train,y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "xvU8m1SFmaIP"
   },
   "outputs": [],
   "source": [
    "# Predict the values from the test set.\n",
    "y_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z5KlZlkKmfxv",
    "outputId": "b7a6493a-1248-4401-b124-43cb2a64fd73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85264\n"
     ]
    }
   ],
   "source": [
    "# Get the accuracy of the predictions on the test set.\n",
    "print(accuracy_score(y_val,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8cKCNNYyp26r",
    "outputId": "a42f7487-da89-405d-8003-0f65f7ab85f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84\n"
     ]
    }
   ],
   "source": [
    "# Test the model on the separate data for comparision with the original model.\n",
    "test_pred=model.predict(vectorizer.transform(test_data))\n",
    "print(accuracy_score(test_pred,test_data_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that these parameters have made a large imporvement on the original model.\n",
    "\n",
    "It has gone from 0.763 to 0.853 in the test data and from 0.74 to 0.84 in the separate test data.\n",
    "\n",
    "The only method we have left to test is the TfidfTransformer, which we can do now with the parameters we have got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "kD54r1pplwup"
   },
   "outputs": [],
   "source": [
    "# Import the TfidfTransformer.\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# Initialize the CountVectorizer with the parameters\n",
    "vectorizer = CountVectorizer(stop_words=stop_words, lowercase=True, max_df=0.8, min_df=0.01, ngram_range=(1,2)) #lowercase=True\n",
    "\n",
    "# Generate the features.\n",
    "features = vectorizer.fit_transform(train_data)\n",
    "\n",
    "# Initialize the TfidfTransformer.\n",
    "tf_idf = TfidfTransformer(use_idf=True,norm='l2', smooth_idf=True)\n",
    "\n",
    "# Fit the data to the TfidfTransformer.\n",
    "tf_idf_features = tf_idf.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AMApfqdV60Jb",
    "outputId": "6e25b71f-a3a8-4039-99f2-24e9265d295e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 1821)\n"
     ]
    }
   ],
   "source": [
    "# Print out the shape of the tf_idf_features to ensure it is the same shape as before.\n",
    "print(tf_idf_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "4wFgJoBfqvSM"
   },
   "outputs": [],
   "source": [
    "# Split the data into train and test the same as the demonstration.\n",
    "X_train, X_val, y_train, y_val = train_test_split(tf_idf_features,train_data_labels,train_size=0.75,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new LogisticRegression model.\n",
    "model = LogisticRegression(max_iter=400)\n",
    "\n",
    "# Train the model on the training data.\n",
    "model = model.fit(X=X_train,y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the values from the test set.\n",
    "y_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87152\n"
     ]
    }
   ],
   "source": [
    "# Get the accuracy of the predictions on the test set.\n",
    "print(accuracy_score(y_val,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.862\n"
     ]
    }
   ],
   "source": [
    "# Test the model on the separate data for comparision with the original model.\n",
    "test_pred=model.predict(tf_idf.transform(vectorizer.transform(test_data)))\n",
    "print(accuracy_score(test_pred,test_data_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that incorporating the TfidfTransformer has further improved the accuracy by 2% for both the test set and the separate test set.\n",
    "\n",
    "In conclusion, the area that the original model could be improved in was mainly the feature representation being fed in to the model. Considering the best representation to get the features which are likely to determine the class of a document will lead to better results. We have found that having a moderate size collection of words, ~1,000 consisting of words that are not very common but occur in a small collection of documents works best. Removing stop words is a good option, but setting a max document frequency will likely remove most of these. Unfortunately, n-gram count was not a very useful option, possibly due to the scarcity of pairs in many documents. Lastly, we can see that considering the tf-idf score worked well and this means that the repeated occurrence of a positve word is not as significant after the first occurrence.\n",
    "\n",
    "This assignment has been interesting and has helped me get a better understanding of the options when pre-processing textual data for a machine learning task."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "08743a7e09354493be8c6bb1ca047e70": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1fdeebdafba14d0c9ab234835739da3f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "368e31f92e0d4d1c87ee49914f1ffc6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_63e5c1aa5ae149ddb658f8dfe71239f4",
       "IPY_MODEL_8f47145a1d2c42bb96b2197cce11156c",
       "IPY_MODEL_9cd069a843c446d6bc9bc289d3aa0b74"
      ],
      "layout": "IPY_MODEL_1fdeebdafba14d0c9ab234835739da3f"
     }
    },
    "63e5c1aa5ae149ddb658f8dfe71239f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cc89fd8c3e9546c48f5c53c5880deb19",
      "placeholder": "",
      "style": "IPY_MODEL_d1a6da014a0e4c7f8361e1beb0b17788",
      "value": "100%"
     }
    },
    "8f47145a1d2c42bb96b2197cce11156c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d73e89c174b64492b4bf6e241948803f",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ab8e3e09052140cda8630e66b1085253",
      "value": 3
     }
    },
    "9cd069a843c446d6bc9bc289d3aa0b74": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_08743a7e09354493be8c6bb1ca047e70",
      "placeholder": "",
      "style": "IPY_MODEL_fb1c08cb7c2d49debc140370ee19e7b5",
      "value": " 3/3 [00:00&lt;00:00, 85.76it/s]"
     }
    },
    "ab8e3e09052140cda8630e66b1085253": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cc89fd8c3e9546c48f5c53c5880deb19": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1a6da014a0e4c7f8361e1beb0b17788": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d73e89c174b64492b4bf6e241948803f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb1c08cb7c2d49debc140370ee19e7b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
